# -*- coding: utf-8 -*-
"""OOP_Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10tE2PJFIK10iwvovgrEsliQiHRXRQX_1
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, f1_score
import pickle

class DataHandler:
    def __init__(self, file_path):
        self.file_path = file_path
        self.data = None
        self.X = None
        self.y = None

    #Load Dataset kita
    def load_data(self):
        self.data = pd.read_csv(self.file_path)

    def preprocess_data(self):
        # Fill missing numerical values with median
        num_cols_to_fill = ['avg_price_per_room', 'required_car_parking_space']
        for col in num_cols_to_fill:
            self.data[col] = self.data[col].fillna(self.data[col].median())

        # Fill missing categorical values with mode
        cat_cols_to_fill = ['type_of_meal_plan']
        for col in cat_cols_to_fill:
            self.data[col] = self.data[col].fillna(self.data[col].mode()[0])

        # Create new features
        self.data['total_nights'] = self.data['no_of_weekend_nights'] + self.data['no_of_week_nights']
        self.data['total_guests'] = self.data['no_of_adults'] + self.data['no_of_children']

        # Create booking season feature based on arrival_month
        def get_season(month):
            if month in [12, 1, 2]:
                return 'Winter'
            elif month in [3, 4, 5]:
                return 'Spring'
            elif month in [6, 7, 8]:
                return 'Summer'
            else:
                return 'Fall'

        self.data['booking_season'] = self.data['arrival_month'].apply(get_season)

        # Drop unnecessary columns
        self.data.drop(['Booking_ID', 'arrival_date', 'arrival_month', 'arrival_year'], axis=1, inplace=True)

        # Prepare features and target
        self.X = self.data.drop('booking_status', axis=1)
        self.y = self.data['booking_status'].map({'Canceled': 1, 'Not_Canceled': 0})

    #Split Data
    def split_data(self, test_size=0.2, random_state=42):
        return train_test_split(self.X, self.y, test_size=test_size, random_state=random_state, stratify=self.y)

class ModelHandler:
    def __init__(self, X_train, X_test, y_train, y_test):
        self.X_train = X_train
        self.X_test = X_test
        self.y_train = y_train
        self.y_test = y_test
        self.model = None
        self.rf_pipeline = None

    def create_model(self):
        # Scaling numerical data
        numerical_transformer = StandardScaler()

        # one hot encode categorical data
        categorical_transformer = Pipeline(steps=[
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ])

        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numerical_transformer, self.X_train.select_dtypes(include=['int64', 'float64']).columns),
                ('cat', categorical_transformer, self.X_train.select_dtypes(include=['object']).columns)
            ])

        # Create pipeline with preprocessor and classifier
        self.rf_pipeline = Pipeline([
            ('preprocessor', preprocessor),
            ('classifier', RandomForestClassifier(random_state=42))
        ])

    #Train Random Forest Model
    def train_model(self):
        self.rf_pipeline.fit(self.X_train, self.y_train)

    def make_prediction(self):
        return self.rf_pipeline.predict(self.X_test)

    #Evaluate Model
    def evaluate_model(self, y_pred):
        print("\nClassification Report:")
        print(classification_report(self.y_test, y_pred))

        accuracy = accuracy_score(self.y_test, y_pred)
        print(f"Accuracy: {accuracy:.4f}")

        # Evaluate ROC AUC and F1 Score
        y_proba = self.rf_pipeline.predict_proba(self.X_test)[:, 1]
        roc_auc = roc_auc_score(self.y_test, y_proba)
        f1 = f1_score(self.y_test, y_pred)

        print(f"ROC AUC: {roc_auc:.4f}")
        print(f"F1-Score: {f1:.4f}")

    #Fine tuning with GridSearchCV
    def tune_model(self):
        param_grid = {
            'classifier__n_estimators': [100, 200],
            'classifier__max_depth': [None, 10, 20],
            'classifier__min_samples_split': [2, 5],
            'classifier__class_weight': [None, 'balanced']
        }

        grid_search = GridSearchCV(
            estimator=self.rf_pipeline,
            param_grid=param_grid,
            scoring='roc_auc',
            cv=3,
            n_jobs=-1,
            verbose=1
        )

        grid_search.fit(self.X_train, self.y_train)
        print("Best Hyperparameters:", grid_search.best_params_)
        self.rf_pipeline = grid_search.best_estimator_

    #Save Model with pickle
    def save_model(self, filename):
        with open(filename, 'wb') as f:
            pickle.dump(self.rf_pipeline, f)

if __name__ == "__main__":
    file_path = 'Dataset_B_hotel.csv'
    data_handler = DataHandler(file_path)
    data_handler.load_data()
    data_handler.preprocess_data()

    X_train, X_test, y_train, y_test = data_handler.split_data()

    model_handler = ModelHandler(X_train, X_test, y_train, y_test)
    model_handler.create_model()

    # Train and evaluate model before tuning
    print("=== Before Hyperparameter Tuning ===")
    model_handler.train_model()
    y_pred = model_handler.make_prediction()
    model_handler.evaluate_model(y_pred)

    # Tune and evaluate model after tuning
    print("\n=== After Hyperparameter Tuning ===")
    model_handler.tune_model()
    model_handler.train_model()
    y_pred = model_handler.make_prediction()
    model_handler.evaluate_model(y_pred)

    # Save trained model nya
    model_handler.save_model('trained_model_rf.pkl')